<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Tiny On-Device Chat â€” WASM (TinyMistral)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    :root{
      --bg:#071021; --card: rgba(255,255,255,0.04); --muted:#9fb0c8; --text:#e6f0fb;
      --accent1:#6ea8ff; --accent2:#6fffd1; --radius:16px;
    }
    *{box-sizing:border-box}
    body{
      margin:0; min-height:100vh; display:flex; align-items:center; justify-content:center;
      background: radial-gradient(800px 400px at 10% -10%, #0e304b 0%, #071021 50%, #04060a 100%);
      font-family: Inter, Roboto, system-ui, -apple-system, "Segoe UI", Arial; color:var(--text); padding:20px;
    }
    .app{
      width:min(980px,100%); border-radius:var(--radius); padding:18px; background:linear-gradient(180deg, rgba(255,255,255,0.03), rgba(255,255,255,0.02));
      border:1px solid rgba(255,255,255,0.04); box-shadow: 0 18px 50px rgba(2,6,23,0.6);
      display:grid; gap:12px; grid-template-rows:auto auto 1fr auto;
    }
    .head{display:flex;align-items:center;gap:12px}
    .logo{width:44px;height:44px;border-radius:10px;display:grid;place-items:center;font-weight:800;color:#03121a;background:linear-gradient(135deg,var(--accent1),var(--accent2));box-shadow:0 8px 26px rgba(110,168,255,0.18)}
    .title{font-size:18px;font-weight:700}
    .sub{color:var(--muted);font-size:13px}
    .progress{display:flex;align-items:center;gap:10px;background:var(--card);padding:10px;border-radius:12px;border:1px solid rgba(255,255,255,0.03)}
    .bar-wrap{flex:1;background:rgba(255,255,255,0.04);height:12px;border-radius:999px;overflow:hidden}
    .bar{height:100%;width:0%;background:linear-gradient(90deg,var(--accent1),var(--accent2));transition:width .12s ease}
    .pct{width:56px;text-align:right;color:var(--muted);font-variant-numeric:tabular-nums}
    .status{color:var(--muted);font-size:13px}
    .chat{background:rgba(255,255,255,0.03);border-radius:12px;padding:12px;min-height:360px;max-height:58vh;overflow:auto;border:1px solid rgba(255,255,255,0.04)}
    .msg{padding:10px 12px;border-radius:12px;max-width:86%;white-space:pre-wrap}
    .me{align-self:flex-end;background:rgba(110,168,255,0.12);border:1px solid rgba(110,168,255,0.25);color:#eaf6ff;margin-left:auto}
    .bot{align-self:flex-start;background:rgba(255,255,255,0.03);border:1px solid rgba(255,255,255,0.06);color:var(--text);margin-right:auto}
    .controls{display:flex;gap:10px;align-items:flex-end}
    .input{flex:1;display:flex;background:var(--card);border-radius:12px;padding:10px;border:1px solid rgba(255,255,255,0.03)}
    textarea{flex:1;background:transparent;border:0;color:var(--text);resize:vertical;min-height:64px;max-height:200px;outline:none;font:inherit}
    button{appearance:none;border:0;padding:10px 14px;border-radius:10px;background:linear-gradient(135deg,var(--accent1),var(--accent2));color:#03121a;font-weight:700;cursor:pointer;box-shadow:0 8px 20px rgba(110,168,255,0.14)}
    button.secondary{background:transparent;border:1px solid rgba(255,255,255,0.04);color:var(--muted)}
    button:disabled{opacity:.5;cursor:not-allowed}
    .tiny{font-size:12px;color:var(--muted)}
  </style>
</head>
<body>
  <div class="app" id="app">
    <div class="head">
      <div class="logo">AI</div>
      <div>
        <div class="title">Tiny On-Device Chat</div>
        <div class="sub">TinyMistral-248M (smallest practical on-device model). WASM CPU â€” works on Android & desktop.</div>
      </div>
      <div style="margin-left:auto;display:flex;gap:8px;align-items:center">
        <div class="tiny" id="modelBadge">Model: TinyMistral-248M Q8_0</div>
      </div>
    </div>

    <div class="progress">
      <div class="status" id="status">Click <b>Load Model</b> to begin</div>
      <div class="bar-wrap" aria-hidden="true"><div class="bar" id="bar"></div></div>
      <div class="pct" id="pct">0%</div>
      <button id="btnLoad">Load Model</button>
    </div>

    <div class="chat" id="chat">
      <div class="msg bot">ðŸ‘‹ Hello â€” model is not loaded yet. Tap <b>Load Model</b> to download (~260 MB) and run locally.</div>
    </div>

    <div class="controls">
      <div class="input">
        <textarea id="prompt" placeholder="Type your messageâ€¦" disabled></textarea>
      </div>
      <div style="display:flex;flex-direction:column;gap:8px">
        <button id="btnSend" disabled>Send</button>
        <button id="btnClear" class="secondary">Clear</button>
      </div>
    </div>

    <div class="tiny">Note: first load downloads and caches the model. Subsequent loads will be faster. If using an Android browser, use Chrome/Edge/Brave for best compatibility.</div>
  </div>

  <script type="module">
    // Uses @wllama/wllama (llama.cpp WASM wrapper).
    import { Wllama, LoggerWithoutDebug } from "https://cdn.jsdelivr.net/npm/@wllama/wllama@2.3.4/esm/index.js";
    import WasmFromCDN from "https://cdn.jsdelivr.net/npm/@wllama/wllama@2.3.4/esm/wasm-from-cdn.js";

    // UI refs
    const statusEl = document.getElementById("status");
    const barEl = document.getElementById("bar");
    const pctEl = document.getElementById("pct");
    const btnLoad = document.getElementById("btnLoad");
    const btnSend = document.getElementById("btnSend");
    const btnClear = document.getElementById("btnClear");
    const promptEl = document.getElementById("prompt");
    const chatEl = document.getElementById("chat");

    // Model choice â€” smallest practical: TinyMistral-248M Q8_0 (~264MB)
    const HF_REPO = "tensorblock/TinyMistral-248M-GGUF";
    const HF_FILE = "TinyMistral-248M-Q8_0.gguf";

    let wllama = null;
    let modelReady = false;
    const history = [];

    function addMsg(text, who = "bot") {
      const d = document.createElement("div");
      d.className = "msg " + (who === "me" ? "me" : "bot");
      d.textContent = text;
      chatEl.appendChild(d);
      chatEl.scrollTop = chatEl.scrollHeight;
      return d;
    }

    function setProgress(percent, label) {
      const p = Math.max(0, Math.min(100, Math.round(percent)));
      barEl.style.width = p + "%";
      pctEl.textContent = p + "%";
      if (label) statusEl.innerHTML = label;
    }

    function setBusy(b) {
      btnSend.disabled = b || !modelReady;
      promptEl.disabled = b || !modelReady;
      btnLoad.disabled = b || modelReady;
    }

    // Build a simple chat-style prompt
    function buildPrompt(userText) {
      const sys = "You are a helpful, concise assistant.";
      const turns = history.map(h => `${h.role.toUpperCase()}: ${h.text}`).join("\n");
      return `${sys}\n${turns}${turns ? "\n" : ""}USER: ${userText}\nASSISTANT:`;
    }

    async function loadModel() {
      if (modelReady) return;
      setBusy(true);
      setProgress(0, "Initializing runtimeâ€¦");

      // Instantiate Wllama (single-threaded for best compatibility)
      wllama = new Wllama(WasmFromCDN, {
        logger: LoggerWithoutDebug,
        parallelDownloads: 4
      });

      // Show low-memory hint for tiny devices
      try { if (navigator.deviceMemory && navigator.deviceMemory < 3) { statusEl.innerHTML = "Warning: low memory device â€” model may fail"; } } catch(e){}

      let lastPct = 0;
      const progressCallback = ({ loaded, total, file, cached }) => {
        const p = total ? (loaded / total) * 100 : lastPct;
        lastPct = p;
        const mb = v => (v / 1024 / 1024).toFixed(1);
        const label = cached
          ? `Loading from cache (${mb(loaded)} MB)`
          : total
            ? `Downloading ${file || "model"} â€” ${mb(loaded)} / ${mb(total)} MB`
            : `Downloadingâ€¦`;
        setProgress(p, label);
      };

      try {
        await wllama.loadModelFromHF(HF_REPO, HF_FILE, {
          n_threads: 1,           // single-thread ensures widest compatibility on Android and file://
          progressCallback
        });

        modelReady = true;
        setProgress(100, "Model loaded â€” ready!");
        addMsg("âœ… Model loaded. Ask me anything!");
        promptEl.disabled = false;
        btnSend.disabled = false;
      } catch (err) {
        console.error("Model load failed:", err);
        setProgress(0, "Model load failed. See console.");
        addMsg("âŒ Failed to load model. Check console and available storage/network.", "bot");
      } finally {
        setBusy(false);
      }
    }

    async function send() {
      const text = promptEl.value.trim();
      if (!text) return;
      history.push({ role: "user", text });
      addMsg(text, "me");
      promptEl.value = "";
      setBusy(true);
      const thinkingNode = addMsg("â€¦thinkingâ€¦", "bot");

      try {
        setProgress(100, "Generating responseâ€¦");
        const prompt = buildPrompt(text);
        // Keep output short/fast for mobile
        const out = await wllama.createCompletion(prompt, {
          nPredict: 160,
          sampling: { temp: 0.7, top_k: 40, top_p: 0.9 },
          stopTokens: ["USER:"]
        });
        const reply = out.trim().replace(/^ASSISTANT:\s*/i, "") || "(no output)";
        thinkingNode.textContent = reply;
        history.push({ role: "assistant", text: reply });
        statusEl.innerHTML = "Ready";
      } catch (err) {
        console.error("Generation error:", err);
        thinkingNode.textContent = "âš ï¸ Error generating reply.";
        statusEl.innerHTML = "Error";
      } finally {
        setBusy(false);
      }
    }

    // UI wiring
    document.getElementById("btnLoad").addEventListener("click", loadModel);
    document.getElementById("btnSend").addEventListener("click", send);
    document.getElementById("btnClear").addEventListener("click", () => {
      history.length = 0;
      chatEl.innerHTML = "";
      addMsg("ðŸ§¹ Cleared. Load model and ask anything!");
    });
    promptEl.addEventListener("keydown", (e) => {
      if (e.key === "Enter" && !e.shiftKey) { e.preventDefault(); send(); }
    });

    // optional: auto attempt to load if not on small mobile user agent (comment out if undesired)
    // if (!/Android|iPhone|iPad/i.test(navigator.userAgent)) { loadModel(); }
  </script>
</body>
</html>
